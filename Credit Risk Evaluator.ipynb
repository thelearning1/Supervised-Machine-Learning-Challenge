{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A tale of two models\n",
    "A wild prediction on which model will test more accurately.\n",
    "\n",
    "Based on my (admmittedly quite limited) understanding, I think the Logistic Regression model will perform better.\n",
    "\n",
    "The time facet of the problem is what I'm fixated on here. Regression is better at anticipating a pattern for future data because its results are not based on mean values. Random Forest averages the values it has already seen, so unless the sample size is large enough to show atypical extremes, it will always stay neatly in the mean of what it already knows. If the line keeps continuing up or down beyond that, it will struggle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "x_train = pd.get_dummies(train_df.drop(columns=['target']))\n",
    "y_train = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "x_test = pd.get_dummies(test_df.drop(columns=['target']))\n",
    "y_test = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "for col in x_train.columns:\n",
    "    if col not in x_test.columns:\n",
    "        x_test[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5070182900893236"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "logreg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6437686091025095"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(x_train,y_train)\n",
    "forest.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts 1 and Prediction 2\n",
    "In hindsight, the second part of the assignment makes a lot more sense to me now and my limited statistical knowledge.\n",
    "\n",
    "Regression performed poorly compared to Forest with scores of .507 and .640 respectively.\n",
    "\n",
    "StandardScaler should make all the predicting datapoints have a centered mean. By my reading, but my own clumsy words: if the data are in a fairly normal distribution (which I believe the loan data should be even though the datasets are heavily truncated to have a roughly even distribution of high and low risk loans), then Regression should improve its performance comparitively because random forest already averages its trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "s_scaler = StandardScaler()\n",
    "s_scaler.fit(x_train)\n",
    "scaled_x_train = s_scaler.transform(x_train)\n",
    "scaled_x_test = s_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598894087622289"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "#same operations as before but on the scaled versions\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(scaled_x_train,y_train)\n",
    "logreg.score(scaled_x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6301573798383666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(scaled_x_train,y_train)\n",
    "forest.score(scaled_x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "I suppose a correct guess, even if it's for the wrong reasons, is a kind of victory.\n",
    "\n",
    "Regression did what I hoped it would do initially with a huge jump to a .759 score while random forest stayed more or less the same, which I also thought would happen.\n",
    "\n",
    "Upon playing with the parameters of StandardScaler (and thinking a little more) it's logical that it was the scaling for standard deviation, not the centering, that greatly benefits the model. This would indicate the data's predictors likely being in a fairly normal distribution. If the distribution is fairly normal, then accounting for the variance of the data will yield far more accurate results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PythonData] *",
   "language": "python",
   "name": "conda-env-.conda-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
